{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protein embeddings improve phage-host interaction prediction\n",
    "\n",
    "**Mark Edward M. Gonzales<sup>1, 2</sup> & Anish M.S. Shrestha<sup>1, 2</sup>**\n",
    "\n",
    "<sup>1</sup> Department of Software Technology, College of Computer Studies, De La Salle University, Manila, Philippines <br>\n",
    "<sup>2</sup> Bioinformatics Laboratory, Advanced Research Institute for Informatics, Computing and Networking, De La Salle University, Manila, Philippines\n",
    "\n",
    "{mark_gonzales, anish.shrestha}@dlsu.edu.ph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ Output Files\n",
    "If you want to skip running this notebook, you may download the protein embeddings from this [Google Drive](https://drive.google.com/drive/folders/1deenrDQIr3xcl9QCYH-nPhmpY8x2drQw?usp=sharing). Save the results inside the `inphared` directory. The folder structure should look like this:\n",
    "\n",
    "`inphared` <br>\n",
    "‚Ü≥ `embeddings` <br>\n",
    "&nbsp; &nbsp; ‚Ü≥ `esm` <br>\n",
    "&nbsp; &nbsp; ‚Ü≥ `esm1b` <br>\n",
    "&nbsp; &nbsp; ‚Ü≥ ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Memory Requirement of Protein Embeddings\n",
    "\n",
    "The memory requirement of loading pretrained protein embeddings may be heavy for some local machines. We recommend running this notebook on [Google Colab](https://colab.research.google.com/) or any cloud-based service with GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YLgiuc5oZcNu",
    "outputId": "37b73e1b-8b7b-4b5b-8747-1c230412a70d"
   },
   "outputs": [],
   "source": [
    "!pip3 install -U pip > /dev/null\n",
    "!pip3 install -U bio_embeddings[all] > /dev/null\n",
    "!pip install scikit_learn==1.0.2\n",
    "!pip install pyyaml==5.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hi4yylSXZf6O"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import date\n",
    "\n",
    "from Bio import SeqIO\n",
    "from bio_embeddings.embed import ProtTransBertBFDEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MTCyLpEbBxWJ",
    "outputId": "58450092-b4bd-4639-f7ea-4d46dc8533dd"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkM73XzOB7MP"
   },
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Generation of Protein Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S43Mg3StZh4N"
   },
   "outputs": [],
   "source": [
    "def compute_protein_embeddings(embedder, fasta_file, results_dir, prefix=''):\n",
    "    names = [record.id for record in SeqIO.parse(fasta_file, 'fasta')]\n",
    "    sequences = [str(record.seq) for record in SeqIO.parse(fasta_file, 'fasta')]\n",
    "\n",
    "    embeddings = [embedder.reduce_per_protein(embedder.embed(sequence)) for sequence in tqdm(sequences)]\n",
    "    embeddings_df = pd.concat([pd.DataFrame({'ID': names}), pd.DataFrame(embeddings)], axis=1)\n",
    "    embeddings_df.to_csv(results_dir + prefix + '-embeddings.csv', index=False)\n",
    "\n",
    "\n",
    "def compute_protein_embeddings_esm(embedder, fasta_file, results_dir, prefix=''):\n",
    "    names = [record.id for record in SeqIO.parse(fasta_file, 'fasta')]\n",
    "    \n",
    "    embeddings = []\n",
    "    \n",
    "    for record in SeqIO.parse(fasta_file, 'fasta'):\n",
    "        sequence = str(record.seq)\n",
    "        if len(sequence) <= 1022:\n",
    "            embedding = embedder.reduce_per_protein(embedder.embed(sequence))\n",
    "        else:\n",
    "            embedding1 = embedder.embed(sequence[:1022])\n",
    "            embedding2 = embedder.embed(sequence[1022:])\n",
    "            embedding = embedder.reduce_per_protein(np.concatenate((embedding1, embedding2)))\n",
    "        \n",
    "        embeddings.append(embedding)\n",
    "\n",
    "    embeddings_df = pd.concat([pd.DataFrame({'ID': names}), pd.DataFrame(embeddings)], axis=1)\n",
    "    embeddings_df.to_csv(results_dir + prefix + '-embeddings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the protein language model. To load other protein language models, refer to the documentation of the [`bio_embeddings`](https://docs.bioembeddings.com/v0.2.3/api/bio_embeddings.embed.html) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HfPGFC17bedX"
   },
   "outputs": [],
   "source": [
    "embedder = ProtTransBertBFDEmbedder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supply the directory names:\n",
    "- `HYPOTHETICAL_FASTA_DIR`: Directory where the FASTA files containing the protein sequences are located\n",
    "- `HYPOTHETICAL_EMBEDDINGS_DIR`: Directory where the CSV files containing the embeddings are to be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MWdkkpilF-gF"
   },
   "outputs": [],
   "source": [
    "HYPOTHETICAL_FASTA_DIR = f''\n",
    "HYPOTHETICAL_EMBEDDINGS_DIR = f''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the FASTA files containing the protein sequences to be embedded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JLNKoLIgF1l2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "hypothetical_fasta_files = os.listdir(HYPOTHETICAL_FASTA_DIR)\n",
    "\n",
    "len(hypothetical_fasta_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the protein embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wNbJ4LawFg9_"
   },
   "outputs": [],
   "source": [
    "IDX_RESUME = 0    # Adjust as needed (e.g., resuming after Google Colab hangs or times out)\n",
    "\n",
    "for hypothetical_file in hypothetical_fasta_files[IDX_RESUME:]:\n",
    "  # -6 because the string \".fasta\" has six characters\n",
    "  compute_protein_embeddings(embedder, f'{HYPOTHETICAL_FASTA_DIR}/{hypothetical_file}', \n",
    "                             HYPOTHETICAL_EMBEDDINGS_DIR,\n",
    "                             f'/{hypothetical_file[:-6]}')\n",
    "  \n",
    "  # Display progress\n",
    "  print(IDX_RESUME, \":\", hypothetical_file)\n",
    "  IDX_RESUME += 1"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
